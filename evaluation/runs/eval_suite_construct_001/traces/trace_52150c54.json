{"schema_version":"0.4.0","trace_id":"52150c54-7025-4b73-aeb3-8efe1d8b9993","created_at_utc":"2026-02-23T20:36:23Z","model":{"hf_id":"meta-llama/Llama-3.2-1B-Instruct","revision":"9213176726f574b556790deb65791e0c5aa438b6","architecture":"LlamaForCausalLM","num_layers":16,"hidden_size":2048,"num_attention_heads":32,"tokenizer_hf_id":"meta-llama/Llama-3.2-1B-Instruct","dtype":"float32","device":"cpu","quantization":{"enabled":false}},"run_config":{"seed":42,"device_requested":"cpu","max_new_tokens":4,"generation":{"do_sample":true,"temperature":0.8,"top_k":50,"top_p":0.95},"summaries":{"hidden":{"enabled":true,"stats":["mean","std","l2_norm_mean","max_abs"],"sketch":{"method":"randproj","dim":32,"seed":0}},"attention":{"enabled":true,"stats":["entropy_mean","entropy_min","entropy_max","concentration_max","concentration_min","collapsed_head_count","focused_head_count"]},"logits":{"enabled":true,"stats":["entropy","top1_top2_margin","topk_probs","top_k_margin","voter_agreement","perplexity","surprisal"],"topk":5}},"sink":{"type":"local_file","target":"/Users/amyb/Documents/github/joe-b-20/corevital/CoreVital/runs/eval_suite_construct_001/traces/trace_52150c54.json"}},"prompt":{"text":"Answer with one token only: What is 2 + 2?","token_ids":[128000,16533,449,832,4037,1193,25,3639,374,220,17,489,220,17,30],"num_tokens":15},"generated":{"output_text":" 4.","token_ids":[220,19,13,128009],"num_tokens":4},"timeline":[{"step_index":15,"token":{"token_id":220,"token_text":" ","is_prompt_token":false},"logits_summary":{"entropy":1.5371848890127535,"top1_top2_margin":0.4465829133987427,"topk":[{"token_id":128009,"token_text":"<|eot_id|>","prob":0.637},{"token_id":220,"token_text":" ","prob":0.19},{"token_id":4815,"token_text":" \n\n","prob":0.081},{"token_id":13625,"token_text":" Four","prob":0.079},{"token_id":720,"token_text":" \n","prob":0.014}],"top_k_margin":0.4465829133987427,"voter_agreement":1.0,"perplexity":2.902276333924382,"surprisal":2.3955377447355186},"layers":[],"extensions":{}},{"step_index":16,"token":{"token_id":19,"token_text":"4","is_prompt_token":false},"logits_summary":{"entropy":-0.0,"top1_top2_margin":1.0,"topk":[{"token_id":19,"token_text":"4","prob":1.0},{"token_id":47,"token_text":"P","prob":0.0},{"token_id":23,"token_text":"8","prob":0.0},{"token_id":27,"token_text":"<","prob":0.0},{"token_id":39,"token_text":"H","prob":0.0}],"top_k_margin":1.0,"voter_agreement":1.0,"perplexity":1.0,"surprisal":-0.0},"layers":[],"extensions":{}},{"step_index":17,"token":{"token_id":13,"token_text":".","is_prompt_token":false},"logits_summary":{"entropy":1.5845153744434528,"top1_top2_margin":0.4746556878089905,"topk":[{"token_id":13,"token_text":".","prob":0.609},{"token_id":271,"token_text":"\n\n","prob":0.134},{"token_id":128009,"token_text":"<|eot_id|>","prob":0.133},{"token_id":382,"token_text":".\n\n","prob":0.123},{"token_id":27,"token_text":"<","prob":0.0}],"top_k_margin":0.4746556878089905,"voter_agreement":0.9999999403953552,"perplexity":2.9990703711085085,"surprisal":0.7152199935725534},"layers":[],"extensions":{}},{"step_index":18,"token":{"token_id":128009,"token_text":"<|eot_id|>","is_prompt_token":false},"logits_summary":{"entropy":-0.0,"top1_top2_margin":1.0,"topk":[{"token_id":128009,"token_text":"<|eot_id|>","prob":1.0},{"token_id":47,"token_text":"P","prob":0.0},{"token_id":23,"token_text":"8","prob":0.0},{"token_id":27,"token_text":"<","prob":0.0},{"token_id":39,"token_text":"H","prob":0.0}],"top_k_margin":1.0,"voter_agreement":1.0,"perplexity":1.0,"surprisal":-0.0},"layers":[],"extensions":{}}],"summary":{"prompt_tokens":15,"generated_tokens":4,"total_steps":19,"elapsed_ms":2043},"warnings":[],"prompt_analysis":{"layers":[{"heads":[],"basin_scores":[0.4996,0.3241,0.4575,0.0992,0.1776,0.1835,0.1549,0.3207,0.0751,0.1183,0.1914,0.1578,0.0441,0.0396,0.0511,0.054,0.1699,0.2564,0.0187,0.0549,0.1565,0.0734,0.0386,0.3586,0.1726,0.1476,0.1767,0.0922,0.0898,0.0109,0.0254,0.0137]},{"heads":[],"basin_scores":[0.2063,0.0719,0.0319,0.1379,0.0132,0.0988,0.0616,0.018,0.0803,0.0231,0.1831,0.1111,0.0398,0.0286,0.0203,0.0603,0.1048,0.1788,0.0144,0.099,0.1568,0.0425,0.0302,0.0302,0.0981,0.0505,0.0272,0.0194,0.1343,0.1005,0.0834,0.1102]},{"heads":[],"basin_scores":[0.0483,0.0113,0.0204,0.0059,0.0951,0.0545,0.0299,0.1084,0.0133,0.0221,0.0974,0.0367,0.049,0.0319,0.0129,0.0125,0.0525,0.0574,0.0403,0.0854,0.0019,0.0087,0.0158,0.042,0.0986,0.0791,0.0114,0.049,0.0286,0.0466,0.0244,0.1319]},{"heads":[],"basin_scores":[0.0664,0.0915,0.0983,0.0466,0.0374,0.0378,0.0677,0.0322,0.2953,0.1163,0.0862,0.0744,0.0998,0.1075,0.0097,0.0505,0.0282,0.1008,0.0576,0.1134,0.0308,0.0614,0.1533,0.0628,0.0336,0.0161,0.1332,0.0692,0.1546,0.0667,0.0529,0.0554]},{"heads":[],"basin_scores":[0.0157,0.1431,0.0619,0.0541,0.1071,0.1229,0.1169,0.0517,0.228,0.1098,0.0788,0.1286,0.1658,0.1081,0.0358,0.0344,0.0325,0.2104,0.0663,0.0297,0.0434,0.0682,0.238,0.0543,0.088,0.0709,0.1269,0.1397,0.1179,0.0269,0.065,0.062]},{"heads":[],"basin_scores":[0.0414,0.053,0.2116,0.27,0.0264,0.0103,0.0329,0.0132,0.0135,0.0099,0.0044,0.0008,0.071,0.1517,0.0493,0.055,0.0559,0.4076,0.3623,0.19,0.1691,0.0331,0.0177,0.0248,0.0767,0.3973,0.0686,0.0484,0.1504,0.1838,0.0585,0.0421]},{"heads":[],"basin_scores":[0.195,0.1572,0.1869,0.3613,0.118,0.1559,0.0381,0.1812,0.0802,0.0857,0.0167,0.0262,0.1028,0.1288,0.0416,0.1382,0.1348,0.1901,0.2537,0.0579,0.135,0.3492,0.3398,0.1405,0.1214,0.0458,0.1331,0.0646,0.2127,0.13,0.1821,0.1567]},{"heads":[],"basin_scores":[0.3518,0.0779,0.4034,0.2023,0.0662,0.0116,0.043,0.1053,0.059,0.0138,0.1969,0.2067,0.0269,0.0939,0.0922,0.2096,0.3342,0.4747,0.206,0.1745,0.0794,0.0475,0.0883,0.1069,0.1132,0.0951,0.1058,0.0713,0.0177,0.0549,0.0807,0.2572]},{"heads":[],"basin_scores":[0.0718,0.0351,0.1066,0.1255,0.0452,0.0856,0.0813,0.0712,0.1381,0.185,0.3971,0.4341,0.3173,0.0674,0.1509,0.0651,0.1466,0.0292,0.0307,0.0405,0.0417,0.0572,0.1273,0.1212,0.0253,0.1297,0.2202,0.0401,0.1178,0.275,0.038,0.0481]},{"heads":[],"basin_scores":[0.0259,0.1455,0.2068,0.1331,0.1364,0.1258,0.1299,0.5827,0.0081,0.0579,0.0469,0.1725,0.2473,0.8416,0.2159,0.1044,0.0208,0.0148,0.0324,0.1302,0.3641,0.0723,0.088,0.0163,0.042,0.178,0.3156,0.0764,0.1815,0.0707,0.1718,0.1096]},{"heads":[],"basin_scores":[0.2088,0.0244,0.0162,0.0584,0.1532,0.1195,0.042,0.2512,0.1557,0.141,0.0112,0.1274,0.0934,0.0275,0.0197,0.0493,0.2221,0.1729,0.1411,0.1706,0.0223,0.0534,0.0471,0.0071,0.0457,0.0312,0.0064,0.0474,0.2006,0.0488,0.016,0.0953]},{"heads":[],"basin_scores":[0.1872,0.077,0.1422,0.1075,0.0524,0.0192,0.0126,0.0296,0.1773,0.1237,0.1865,0.1569,0.0124,0.0125,0.0366,0.0387,0.1465,0.0735,0.0084,0.075,0.033,0.0352,0.033,0.0382,0.0524,0.0336,0.028,0.1382,0.093,0.0903,0.123,0.0356]},{"heads":[],"basin_scores":[0.1083,0.1949,0.0986,0.2257,0.09,0.1445,0.2263,0.1296,0.2291,0.3698,0.1497,0.5631,0.0131,0.0323,0.0156,0.034,0.1915,0.2324,0.0252,0.2081,0.1023,0.0949,0.1685,0.1307,0.0469,0.0628,0.0565,0.0351,0.0472,0.0199,0.038,0.0197]},{"heads":[],"basin_scores":[0.0647,0.0177,0.0152,0.0997,0.0366,0.0721,0.0764,0.0396,0.1185,0.1905,0.2259,0.2654,0.0273,0.0232,0.0243,0.1977,0.2682,0.2248,0.1849,0.0671,0.0347,0.0312,0.0444,0.1254,0.0644,0.0333,0.0928,0.0845,0.0964,0.1099,0.2173,0.0202]},{"heads":[],"basin_scores":[0.0216,0.1457,0.0107,0.0236,0.3186,0.2506,0.1594,0.0747,0.0432,0.0184,0.1665,0.0201,0.0056,0.0201,0.0196,0.0102,0.067,0.237,0.6102,0.2435,0.0577,0.023,0.0393,0.1637,0.2119,0.3412,0.0469,0.134,0.0151,0.0165,0.0113,0.012]},{"heads":[],"basin_scores":[0.279,0.1856,0.1745,0.1841,0.0217,0.051,0.2713,0.0406,0.2696,0.103,0.0712,0.2325,0.0226,0.0366,0.4377,0.0369,0.0169,0.0476,0.0779,0.0281,0.0145,0.01,0.0226,0.2372,0.2186,0.2712,0.1674,0.0657,0.0398,0.0141,0.0163,0.0167]}],"layer_transformations":[0.371121,0.281555,0.292125,0.271838,0.245535,0.21511,0.195618,0.227116,0.194744,0.16881,0.143172,0.123812,0.114166,0.119056,0.532252],"prompt_surprisals":[16.2757,9.8392,6.9371,18.5523,10.8933,4.13,9.8609,0.7862,6.3497,1.6265,3.0279,0.0369,0.2745,1.053]},"health_flags":{"nan_detected":false,"inf_detected":false,"attention_collapse_detected":true,"high_entropy_steps":0,"repetition_loop_detected":false,"mid_layer_anomaly_detected":false},"extensions":{"risk":{"risk_score":0.3,"risk_factors":["attention_collapse"],"blamed_layers":[0,2,5]},"fingerprint":{"vector":[0.7804250658640516,1.5845153744434528,0.0,0.3,0.0,0.0,1.0,0.0,0.0],"prompt_hash":"550e6378cf8077a363160626834ca5a72ed2951e633a47b94c8fac53db351fdf"},"early_warning":{"failure_risk":0.3,"warning_signals":["attention_collapse"]},"narrative":{"summary":"This run was low risk. Layers with anomalies or collapse: L0, L2, L5."}}}