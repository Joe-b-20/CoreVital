{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Try CoreVital\n",
        "\n",
        "Run this notebook in Google Colab to try CoreVital in under 2 minutes. No GPU required.\n",
        "\n",
        "CoreVital instruments LLM inference to capture hidden states, attention patterns, and logits,\n",
        "then computes health flags, risk scores, and human-readable narratives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install CoreVital from GitHub (force-reinstall ensures the correct branch code)\n",
        "!pip uninstall -y CoreVital 2>/dev/null\n",
        "!pip install --force-reinstall --no-cache-dir \"git+https://github.com/Joe-b-20/CoreVital.git@release/showcase\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Verify installation\n",
        "import CoreVital\n",
        "print(f\"CoreVital {CoreVital.__version__} installed at {CoreVital.__file__}\")\n",
        "print(f\"CoreVitalMonitor available: {hasattr(CoreVital, 'CoreVitalMonitor')}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from CoreVital import CoreVitalMonitor\n",
        "\n",
        "monitor = CoreVitalMonitor(capture_mode=\"summary\", max_new_tokens=20)\n",
        "\n",
        "# Change this prompt to anything you want\n",
        "PROMPT = \"Explain why the sky is blue in one sentence.\"\n",
        "\n",
        "monitor.run(\"gpt2\", PROMPT)\n",
        "\n",
        "print(\"Generated:\", monitor.get_report().generated.output_text)\n",
        "print()\n",
        "print(\"Risk score:\", monitor.get_risk_score())\n",
        "print(\"Health flags:\", monitor.get_health_flags())\n",
        "print(\"Narrative:\", monitor.get_summary().get(\"narrative\", {}).get(\"summary\", \"\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Inspect the full report\n",
        "report = monitor.get_report()\n",
        "\n",
        "print(f\"Model: {report.model.hf_id} ({report.model.num_layers} layers)\")\n",
        "print(f\"Prompt tokens: {report.summary.prompt_tokens}\")\n",
        "print(f\"Generated tokens: {report.summary.generated_tokens}\")\n",
        "print(f\"Wall time: {report.summary.elapsed_ms:.0f} ms\")\n",
        "print()\n",
        "\n",
        "# Per-step entropy curve\n",
        "for step in report.timeline:\n",
        "    ent = step.logits_summary.entropy if step.logits_summary else None\n",
        "    tok = step.token.token_text if step.token else \"?\"\n",
        "    print(f\"  step {step.step_index:2d}  token={tok:<15s}  entropy={ent:.2f}\" if ent else f\"  step {step.step_index:2d}  token={tok}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Health-aware decoding: should the system intervene?\n",
        "monitor_strict = CoreVitalMonitor(\n",
        "    capture_mode=\"summary\",\n",
        "    max_new_tokens=20,\n",
        "    intervene_on_risk_above=0.7,\n",
        ")\n",
        "monitor_strict.run(\"gpt2\", \"The meaning of life is\")\n",
        "\n",
        "print(\"Risk:\", monitor_strict.get_risk_score())\n",
        "print(\"Should intervene:\", monitor_strict.should_intervene())\n",
        "print(\"Output:\", monitor_strict.get_report().generated.output_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps\n",
        "\n",
        "- **Dashboard:** Install locally and run `streamlit run dashboard.py` to visualize reports\n",
        "- **Production models:** Try with Llama, Mistral, or Qwen (requires more memory or GPU)\n",
        "- **Docs:** See the [README](https://github.com/Joe-b-20/CoreVital) for CLI usage, configuration, and architecture"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}